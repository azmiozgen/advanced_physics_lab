{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "import new_approach\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on training data: 47028 / 50000\n",
      "Accuracy on evaluation data: 9402 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Accuracy on training data: 47574 / 50000\n",
      "Accuracy on evaluation data: 9451 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Accuracy on training data: 47940 / 50000\n",
      "Accuracy on evaluation data: 9548 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Accuracy on training data: 47764 / 50000\n",
      "Accuracy on evaluation data: 9476 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Accuracy on training data: 48085 / 50000\n",
      "Accuracy on evaluation data: 9534 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Accuracy on training data: 48038 / 50000\n",
      "Accuracy on evaluation data: 9536 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Accuracy on training data: 48016 / 50000\n",
      "Accuracy on evaluation data: 9520 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Accuracy on training data: 48016 / 50000\n",
      "Accuracy on evaluation data: 9533 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Accuracy on training data: 48253 / 50000\n",
      "Accuracy on evaluation data: 9540 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Accuracy on training data: 48323 / 50000\n",
      "Accuracy on evaluation data: 9582 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Accuracy on training data: 48211 / 50000\n",
      "Accuracy on evaluation data: 9563 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Accuracy on training data: 48414 / 50000\n",
      "Accuracy on evaluation data: 9593 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Accuracy on training data: 48213 / 50000\n",
      "Accuracy on evaluation data: 9535 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Accuracy on training data: 48365 / 50000\n",
      "Accuracy on evaluation data: 9566 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Accuracy on training data: 48304 / 50000\n",
      "Accuracy on evaluation data: 9569 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Accuracy on training data: 48168 / 50000\n",
      "Accuracy on evaluation data: 9550 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Accuracy on training data: 48050 / 50000\n",
      "Accuracy on evaluation data: 9535 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Accuracy on training data: 48435 / 50000\n",
      "Accuracy on evaluation data: 9585 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Accuracy on training data: 48443 / 50000\n",
      "Accuracy on evaluation data: 9618 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Accuracy on training data: 48276 / 50000\n",
      "Accuracy on evaluation data: 9580 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Accuracy on training data: 48137 / 50000\n",
      "Accuracy on evaluation data: 9538 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Accuracy on training data: 48517 / 50000\n",
      "Accuracy on evaluation data: 9617 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Accuracy on training data: 48260 / 50000\n",
      "Accuracy on evaluation data: 9551 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Accuracy on training data: 48458 / 50000\n",
      "Accuracy on evaluation data: 9606 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Accuracy on training data: 48438 / 50000\n",
      "Accuracy on evaluation data: 9585 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Accuracy on training data: 48376 / 50000\n",
      "Accuracy on evaluation data: 9591 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Accuracy on training data: 48569 / 50000\n",
      "Accuracy on evaluation data: 9629 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Accuracy on training data: 48341 / 50000\n",
      "Accuracy on evaluation data: 9559 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Accuracy on training data: 48458 / 50000\n",
      "Accuracy on evaluation data: 9616 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Accuracy on training data: 48453 / 50000\n",
      "Accuracy on evaluation data: 9617 / 10000\n",
      "\n",
      "1277.19382811\n"
     ]
    }
   ],
   "source": [
    "net1 = new_approach.Network([784, 30, 10], cost=new_approach.CrossEntropyCost)\n",
    "# net.large_weight_initializer()\n",
    "\n",
    "t1 = time.time()\n",
    "eval_cost1, eval_acc1, train_cost1, train_acc1 = \\\n",
    "net1.SGD(training_data, 30, 10, 0.5, dropout=False, lmbda = 0.0, \n",
    "evaluation_data=test_data, monitor_evaluation_cost=False, monitor_evaluation_accuracy=True,\n",
    "monitor_training_cost=False, monitor_training_accuracy=True)\n",
    "print time.time() - t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net2 = new_approach.Network([784, 30, 10], cost=new_approach.CrossEntropyCost)\n",
    "# net.large_weight_initializer()\n",
    "\n",
    "t1 = time.time()\n",
    "eval_cost2, eval_acc2, train_cost2, train_acc2 = \\\n",
    "net2.SGD(training_data, 30, 10, 0.5, dropout=True, lmbda = 5.0, \n",
    "evaluation_data=test_data, monitor_evaluation_cost=False, monitor_evaluation_accuracy=True,\n",
    "monitor_training_cost=False, monitor_training_accuracy=True)\n",
    "print time.time() - t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(30), eval_acc1, \"b\", label=\"no dropout (1277 sec)\")\n",
    "plt.plot(range(30), eval_acc2, \"r\", label=\"random dropout (1240 sec)\")\n",
    "plt.title(\"Dropout effect on test accuracy (train size=50000, test size=10000, epoch=30)\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"test accuracy\")\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(net1.dropVector[0] == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 1])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.dropVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 1, 0])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.dropVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(len(net2.dropVector[0])) / len(np.where(net2.dropVector[0] == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(net2.dropVector[0] == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netTest = new_approach.Network([784, 30, 10], cost=new_approach.CrossEntropyCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for hiddenLayerSize in netTest.sizes[1:-1]:\n",
    "    netTest.dropVector = [np.random.randint(2, size=hiddenLayerSize)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netTest.dropVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(netTest.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(784, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zs = []\n",
    "activations =[]\n",
    "def sigmoid(z):\n",
    "    '''\n",
    "    The sigmoid function.\n",
    "    '''\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "sigmoid_vec = np.vectorize(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1])]\n",
      "[[-1.54967161]\n",
      " [ 2.49850023]\n",
      " [-0.67236347]\n",
      " [-0.06461447]\n",
      " [ 0.42436382]\n",
      " [-2.8327241 ]\n",
      " [-0.92861658]\n",
      " [-0.45368473]\n",
      " [-0.19608731]\n",
      " [-0.0541801 ]\n",
      " [-0.59036331]\n",
      " [ 0.64799512]\n",
      " [-0.61443128]\n",
      " [ 0.68599589]\n",
      " [-1.21803673]\n",
      " [-1.89318599]\n",
      " [-1.11393011]\n",
      " [-1.19904341]\n",
      " [ 1.07323665]\n",
      " [-0.11962476]\n",
      " [ 0.72488075]\n",
      " [-0.48293636]\n",
      " [ 0.66770516]\n",
      " [-0.68003962]\n",
      " [ 0.79385095]\n",
      " [ 1.30368163]\n",
      " [ 1.82917159]\n",
      " [ 1.37776351]\n",
      " [ 0.51228415]\n",
      " [ 0.57432821]]\n",
      "[[-0.        ]\n",
      " [ 2.49850023]\n",
      " [-0.67236347]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.45368473]\n",
      " [-0.19608731]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.68599589]\n",
      " [-0.        ]\n",
      " [-1.89318599]\n",
      " [-1.11393011]\n",
      " [-1.19904341]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 1.30368163]\n",
      " [ 1.82917159]\n",
      " [ 1.37776351]\n",
      " [ 0.51228415]\n",
      " [ 0.57432821]]\n",
      "[[ 0.5       ]\n",
      " [ 0.92403661]\n",
      " [ 0.33796782]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.38848505]\n",
      " [ 0.45113465]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.6650756 ]\n",
      " [ 0.5       ]\n",
      " [ 0.13088163]\n",
      " [ 0.24713892]\n",
      " [ 0.23164543]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.5       ]\n",
      " [ 0.78645394]\n",
      " [ 0.86166301]\n",
      " [ 0.79863157]\n",
      " [ 0.62534178]\n",
      " [ 0.63976129]]\n",
      "[[ 0.        ]\n",
      " [ 2.13239218]\n",
      " [ 0.77992575]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.89650395]\n",
      " [ 1.04107995]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 1.53478985]\n",
      " [ 0.        ]\n",
      " [ 0.30203453]\n",
      " [ 0.57032059]\n",
      " [ 0.53456638]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 1.81489371]\n",
      " [ 1.9884531 ]\n",
      " [ 1.84299593]\n",
      " [ 1.44309641]\n",
      " [ 1.4763722 ]]\n",
      "[[-0.49337526]\n",
      " [ 0.35032496]\n",
      " [ 1.80400415]\n",
      " [ 0.7555112 ]\n",
      " [-0.16172008]\n",
      " [ 1.21905446]\n",
      " [-0.68387432]\n",
      " [-0.49778988]\n",
      " [ 1.29444737]\n",
      " [ 3.49308575]]\n",
      "[[-0.49337526]\n",
      " [ 0.35032496]\n",
      " [ 1.80400415]\n",
      " [ 0.7555112 ]\n",
      " [-0.16172008]\n",
      " [ 1.21905446]\n",
      " [-0.68387432]\n",
      " [-0.49778988]\n",
      " [ 1.29444737]\n",
      " [ 3.49308575]]\n",
      "[[ 0.37909877]\n",
      " [ 0.58669638]\n",
      " [ 0.85863566]\n",
      " [ 0.68037838]\n",
      " [ 0.45965787]\n",
      " [ 0.77189711]\n",
      " [ 0.33539714]\n",
      " [ 0.3780602 ]\n",
      " [ 0.784899  ]\n",
      " [ 0.9704904 ]]\n",
      "[[ 0.37909877]\n",
      " [ 0.58669638]\n",
      " [ 0.85863566]\n",
      " [ 0.68037838]\n",
      " [ 0.45965787]\n",
      " [ 0.77189711]\n",
      " [ 0.33539714]\n",
      " [ 0.3780602 ]\n",
      " [ 0.784899  ]\n",
      " [ 0.9704904 ]]\n"
     ]
    }
   ],
   "source": [
    "activation = x\n",
    "print netTest.dropVector\n",
    "for b, w in zip(netTest.biases, netTest.weights):\n",
    "    z = np.dot(w, activation) + b\n",
    "    print z\n",
    "    if len(b) != netTest.sizes[-1]: # if dropout\n",
    "        z = np.multiply(netTest.dropVector, z.transpose()).reshape(-1, 1)\n",
    "    print z\n",
    "    zs.append(z)\n",
    "    activation = sigmoid_vec(z)\n",
    "    print activation\n",
    "    if len(b) != netTest.sizes[-1]: # if dropout\n",
    "        activation = np.multiply(netTest.dropVector, activation.transpose()).reshape(-1, 1)\n",
    "        activation *= float(len(netTest.dropVector[0])) / len(np.where(netTest.dropVector[0] == 1)[0])\n",
    "    print activation\n",
    "    activations.append(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    }
   ],
   "source": [
    "for b, w in zip(netTest.biases, netTest.weights):\n",
    "    if len(b) != netTest.sizes[-1]:\n",
    "        print len(b), len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.        ],\n",
      "       [ 0.92403661],\n",
      "       [ 0.33796782],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.38848505],\n",
      "       [ 0.45113465],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.6650756 ],\n",
      "       [ 0.        ],\n",
      "       [ 0.13088163],\n",
      "       [ 0.24713892],\n",
      "       [ 0.23164543],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.78645394],\n",
      "       [ 0.86166301],\n",
      "       [ 0.79863157],\n",
      "       [ 0.62534178],\n",
      "       [ 0.63976129]]), array([[ 0.5963199 ],\n",
      "       [ 0.53761023],\n",
      "       [ 0.76037244],\n",
      "       [ 0.61659578],\n",
      "       [ 0.52088949],\n",
      "       [ 0.81541458],\n",
      "       [ 0.33889126],\n",
      "       [ 0.49079525],\n",
      "       [ 0.76318399],\n",
      "       [ 0.93390915]])]\n",
      "[array([[ 0.        ],\n",
      "       [ 2.13239218],\n",
      "       [ 0.77992575],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.89650395],\n",
      "       [ 1.04107995],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 1.53478985],\n",
      "       [ 0.        ],\n",
      "       [ 0.30203453],\n",
      "       [ 0.57032059],\n",
      "       [ 0.53456638],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 1.81489371],\n",
      "       [ 1.9884531 ],\n",
      "       [ 1.84299593],\n",
      "       [ 1.44309641],\n",
      "       [ 1.4763722 ]]), array([[ 0.5963199 ],\n",
      "       [ 0.53761023],\n",
      "       [ 0.76037244],\n",
      "       [ 0.61659578],\n",
      "       [ 0.52088949],\n",
      "       [ 0.81541458],\n",
      "       [ 0.33889126],\n",
      "       [ 0.49079525],\n",
      "       [ 0.76318399],\n",
      "       [ 0.93390915]])]\n"
     ]
    }
   ],
   "source": [
    "for index, hiddenLayerSize in enumerate(netTest.sizes[1:-1]):\n",
    "    activations[index] = np.multiply(netTest.dropVector, activations[index].transpose()).reshape(-1, 1)\n",
    "#     print activations\n",
    "#     activations[index] = np.array(activations[index]) * \\\n",
    "#                          float(len(netTest.dropVector[0])) / len(np.where(netTest.dropVector[0] == 1)[0])\n",
    "#     print activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3076923076923075"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(len(netTest.dropVector[0])) / len(np.where(netTest.dropVector[0] == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netTest.dropVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3076923076923075"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30 / 13."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
